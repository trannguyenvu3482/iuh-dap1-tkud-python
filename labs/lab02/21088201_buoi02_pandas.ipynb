{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bai tap buoi 2 - Pandas\n",
    "## Tran Nguyen Vu - 21088201 - STT: 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas data series - Ex 26 to 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "# 26. Write a Pandas program to compute difference of differences between consecutive numbers of a given series.\n",
    "input_series = pd.Series([1.0, 3.0, 5.0, 8.0, 10.0, 11.0, 15.0])\n",
    "\n",
    "print(input_series.diff().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"02-02-2011\" doesn't match format \"%d %b %Y\", at position 1. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m input_series \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01 Jan 2010\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02-02-2011\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20120303\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2013/04/04\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2014-05-05\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2015-06-06T12:20\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_series\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    457\u001b[0m     arg,\n\u001b[0;32m    458\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"02-02-2011\" doesn't match format \"%d %b %Y\", at position 1. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# 27. Write a Pandas program to convert a series of date strings to a timeseries.\n",
    "import datetime as dt\n",
    "\n",
    "input_series = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "print(pd.to_datetime(input_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day of month: \n",
      " [1, 2, 3, 4, 5, 6]\n",
      "Day of year: \n",
      " [1, 33, 63, 94, 125, 157]\n",
      "Week number: \n",
      " [53, 5, 9, 14, 19, 23]\n",
      "Day of week: \n",
      " [4, 2, 5, 3, 0, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8410/4088457313.py:5: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  print(\"Week number: \\n\", pd.to_datetime(input_series).dt.weekofyear.tolist())\n"
     ]
    }
   ],
   "source": [
    "# 28. Write a Pandas program to get the day of month, day of year, week number and day of week from a given series of date strings.\n",
    "input_series = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "print(\"Day of month: \\n\", pd.to_datetime(input_series).dt.day.tolist())\n",
    "print(\"Day of year: \\n\", pd.to_datetime(input_series).dt.dayofyear.tolist())\n",
    "print(\"Week number: \\n\", pd.to_datetime(input_series).dt.weekofyear.tolist())\n",
    "print(\"Day of week: \\n\", pd.to_datetime(input_series).dt.dayofweek.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2015-01-11\n",
      "1   2016-02-11\n",
      "2   2017-03-11\n",
      "3   2018-04-11\n",
      "4   2019-05-11\n",
      "5   2020-06-11\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# 29. Write a Pandas program to convert year-month string to dates adding a specified day of the month.\n",
    "input_series = pd.Series(['Jan 2015', 'Feb 2016', 'Mar 2017', 'Apr 2018', 'May 2019', 'Jun 2020'])\n",
    "\n",
    "print(pd.to_datetime(input_series.map(lambda x: '11 ' + x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     Green\n",
      "2    Orange\n",
      "4    Yellow\n",
      "5     White\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 30. Write a Pandas program to filter words from a given series that contain atleast two vowels.\n",
    "input_series = pd.Series(['Red', 'Green', 'Orange', 'Pink', 'Yellow','White'])\n",
    "\n",
    "def hasAtLeastTwoVowels(word):\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    count = 0\n",
    "    for letter in word:\n",
    "        if letter in vowels:\n",
    "            count += 1\n",
    "    return count >= 2\n",
    "\n",
    "filtered_series = input_series[input_series.apply(hasAtLeastTwoVowels)]\n",
    "\n",
    "print(filtered_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance:  16.492422502470642\n"
     ]
    }
   ],
   "source": [
    "# 31. Write a Pandas program to compute the Euclidean distance between two given series.\n",
    "# Euclidean distance\n",
    "# From Wikipedia,\n",
    "# In mathematics, the Euclidean distance or Euclidean metric is the \"ordinary\" straight-line distance between two points in Euclidean space. With this distance, Euclidean space becomes a metric space. The associated norm is called the Euclidean norm.\n",
    "import math as m\n",
    "series_one = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "series_two = pd.Series([11, 8, 7, 5, 6, 5, 3, 4, 7, 1])\n",
    "\n",
    "euclidean_distance = m.sqrt(sum((series_one - series_two)**2))\n",
    "\n",
    "print(\"Euclidean distance: \", euclidean_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panda dataframe - Ex 61 to 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "5    11     0    11\n",
      "4     7     5     1\n",
      "3     4     9    12\n",
      "   col1  col2  col3\n",
      "3     4     9    12\n",
      "2     3     6     8\n",
      "1     2     5     5\n",
      "4     7     5     1\n",
      "   col1  col2  col3\n",
      "3     4     9    12\n",
      "5    11     0    11\n",
      "2     3     6     8\n"
     ]
    }
   ],
   "source": [
    "# 61. Write a Pandas program to get topmost\n",
    "# n records within each group of a DataFrame.\n",
    "\n",
    "original_df = pd.DataFrame({\n",
    "    'col1': [1, 2, 3, 4, 7, 11],\n",
    "    'col2': [4, 5, 6, 9, 5, 0],\n",
    "    'col3': [7, 5, 8, 12, 1, 11]\n",
    "})\n",
    "\n",
    "n = 3\n",
    "\n",
    "for i in range(n):\n",
    "    print(original_df.nlargest(n, f'col{i+1}', keep='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "3     4     9    12\n",
      "4     7     5     1\n",
      "5    11     0    11\n"
     ]
    }
   ],
   "source": [
    "# 62. Write a Pandas program to remove first n rows of a given DataFrame.\n",
    "original_df = pd.DataFrame({\n",
    "    'col1': [1, 2, 3, 4, 7, 11],\n",
    "    'col2': [4, 5, 6, 9, 5, 0],\n",
    "    'col3': [7, 5, 8, 12, 1, 11]\n",
    "})\n",
    "\n",
    "n = 3\n",
    "\n",
    "print(original_df.iloc[n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     4     7\n",
      "1     2     5     5\n",
      "2     3     6     8\n"
     ]
    }
   ],
   "source": [
    "# 63. Write a Pandas program to remove last n rows of a given DataFrame.\n",
    "\n",
    "original_df = pd.DataFrame({\n",
    "    'col1': [1, 2, 3, 4, 7, 11],\n",
    "    'col2': [4, 5, 6, 9, 5, 0],\n",
    "    'col3': [7, 5, 8, 12, 1, 11]\n",
    "})\n",
    "\n",
    "n = 3\n",
    "\n",
    "print(original_df.iloc[:-n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A_W  A_X  A_Y  A_Z\n",
      "0   68   78   84   86\n",
      "1   75   85   94   97\n",
      "2   86   96   89   96\n",
      "3   80   80   83   72\n",
      "4   66   86   86   83\n",
      "   W_1  X_1  Y_1  Z_1\n",
      "0   68   78   84   86\n",
      "1   75   85   94   97\n",
      "2   86   96   89   96\n",
      "3   80   80   83   72\n",
      "4   66   86   86   83\n"
     ]
    }
   ],
   "source": [
    "# 64. Write a Pandas program to add a prefix or suffix to all columns of a given DataFrame.\n",
    "\n",
    "original_df = pd.DataFrame({\n",
    "    'W': [68, 75, 86, 80, 66],\n",
    "    'X': [78, 85, 96, 80, 86],\n",
    "    'Y': [84, 94, 89, 83, 86],\n",
    "    'Z': [86, 97, 96, 72, 83],\n",
    "})\n",
    "\n",
    "print(original_df.add_prefix('A_'))\n",
    "print(original_df.add_suffix('_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    W   X   Y   Z\n",
      "0  66  86  86  83\n",
      "1  80  80  83  72\n",
      "2  86  96  89  96\n",
      "3  75  85  94  97\n",
      "4  68  78  84  86\n"
     ]
    }
   ],
   "source": [
    "# 65. Write a Pandas program to reverse order (rows, columns) of a given DataFrame.\n",
    "\n",
    "original_df = pd.DataFrame({\n",
    "    'W': [68, 75, 86, 80, 66],\n",
    "    'X': [78, 85, 96, 80, 86],\n",
    "    'Y': [84, 94, 89, 83, 86],\n",
    "    'Z': [86, 97, 96, 72, 83],\n",
    "})\n",
    "\n",
    "print(original_df.iloc[::-1].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age\n",
      "0  18.5\n",
      "1  21.2\n",
      "2  22.5\n",
      "3  22.0\n",
      "4  23.0\n",
      "             name date_of_birth\n",
      "0  Alberto Franco    2002/05/17\n",
      "1    Gino Mcneill    1999/02/16\n",
      "2     Ryan Parkes    1998/09/25\n",
      "3    Eesha Hinton    2002/05/11\n",
      "4    Syed Wharton    1997/09/15\n"
     ]
    }
   ],
   "source": [
    "# 66. Write a Pandas program to select columns by data type of a given DataFrame.\n",
    "\n",
    "original_df = pd.DataFrame({\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Syed Wharton'],\n",
    "    'date_of_birth': ['2002/05/17', '1999/02/16', '1998/09/25', '2002/05/11', '1997/09/15'],\n",
    "    'age': [18.5, 21.2, 22.5, 22.0, 23.0]\n",
    "})\n",
    "\n",
    "print(original_df.select_dtypes(include='number'))\n",
    "print(original_df.select_dtypes(include='object'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas indexing - Ex 6 to 11 (Unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataframe\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              school_code class            name  weight  address t_id\n",
      "date_Of_Birth                                                        \n",
      "15/05/2002           s001     V  Alberto Franco      35  street1   t1\n",
      "17/05/2002           s002     V    Gino Mcneill      32  street2   t2\n",
      "16/02/1999           s003    VI     Ryan Parkes      33  street3   t3\n",
      "25/09/1998           s001    VI    Eesha Hinton      30  street1   t4\n",
      "11/05/2002           s002     V    Gino Mcneill      31  street2   t5\n",
      "15/09/1997           s004    VI    David Parkes      32  street4   t6\n"
     ]
    }
   ],
   "source": [
    "# 6. Write a Pandas program to create a dataframe indexing by date and time.\n",
    "\n",
    "print(df.set_index('date_Of_Birth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      school_code class            name date_Of_Birth  weight  address t_id\n",
      "index                                                                      \n",
      "0            s001     V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "1            s002     V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "2            s003    VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
      "3            s001    VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "4            s002     V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "5            s004    VI    David Parkes    15/09/1997      32  street4   t6\n"
     ]
    }
   ],
   "source": [
    "# 7. Write a Pandas program to create a dataframe and set a title or name of the index column.\n",
    "df.index.name = 'index'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      school_code class            name date_Of_Birth  weight  address t_id\n",
      "index                                                                      \n",
      "0            s001     V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "1            s002     V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "2            s003    VI            John    16/02/1999      33  street3   t3\n",
      "3            s001    VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "4            s002     V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "5            s004    VI    David Parkes    15/09/1997      32  street4   t6\n"
     ]
    }
   ],
   "source": [
    "# 8. Write a Pandas program to set value in a specific cell in a given dataframe using index.\n",
    "\n",
    "index = 2\n",
    "column = 'name'\n",
    "newValue = 'John Doe'\n",
    "\n",
    "df.at[index, column] = newValue\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index school_code class            name date_Of_Birth  weight  address t_id\n",
      "0      0        s001     V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "1      1        s002     V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "2      2        s003    VI            John    16/02/1999      33  street3   t3\n",
      "3      3        s001    VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "4      4        s002     V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "5      5        s004    VI    David Parkes    15/09/1997      32  street4   t6\n"
     ]
    }
   ],
   "source": [
    "# 9. Write a Pandas program to convert index of a given dataframe into a column.\n",
    "df.reset_index(level=0, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            t_id class            name date_Of_Birth  weight  address\n",
      "school_code                                                          \n",
      "s001          t1     V  Alberto Franco    15/05/2002      35  street1\n",
      "s002          t2     V    Gino Mcneill    17/05/2002      32  street2\n",
      "s003          t3    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "s001          t4    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "s002          t5     V    Gino Mcneill    11/05/2002      31  street2\n",
      "s004          t6    VI    David Parkes    15/09/1997      32  street4\n"
     ]
    }
   ],
   "source": [
    "# 10. Write a Pandas program to convert 1st and 3rd levels in the index\n",
    "# into columns from a multiple level of index frame of a given dataframe.\n",
    "# Create a multi-index DataFrame\n",
    "\n",
    "# Reset df\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
    "\n",
    "# Create multi-index DataFrame\n",
    "df1 = df.set_index(['t_id', 'school_code', 'class'])\n",
    "\n",
    "# Convert the 1st and 3rd levels in the index into columns\n",
    "df2 = df1.reset_index(['t_id', 'class'])\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3 is in single-column index df: True\n",
      "t7 is in single-column index df: False\n",
      "t2 is in multi-column index df: True\n",
      "t2 is in multi-column index df: False\n",
      "t2 is in multi-column index df: False\n"
     ]
    }
   ],
   "source": [
    "# 11. Write a Pandas program to check if a specified value\n",
    "# exists in single and multiple column index dataframe.\n",
    "\n",
    "# Reset df\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
    "\n",
    "# Create df1 from df, then convert df1 to using 't_id' as index\n",
    "df = df.set_index('t_id')\n",
    "\n",
    "# Check a value is exist in single column index dataframe\n",
    "print('t3 is in single-column index df:', 't1' in df1.index)\n",
    "print('t7 is in single-column index df:', 't7' in df1.index)\n",
    "\n",
    "# Reset df\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
    "\n",
    "# Create multi-index DataFrame\n",
    "df2 = df.set_index(['t_id', 'school_code', 'class'])\n",
    "\n",
    "# Check a value is exist in multi-column index dataframe\n",
    "print('t2 is in multi-column index df:', 't2' in df2.index.levels[0])\n",
    "print('t2 is in multi-column index df:', 't2' in df2.index.levels[1])\n",
    "print('t2 is in multi-column index df:', 't2' in df2.index.levels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Joining and merging DataFrame - Ex 1 to 6 (Unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframes\n",
    "student_data1 = pd.DataFrame({\n",
    "    'student_id': ['S1','S2','S3','S4','S5'],\n",
    "    'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
    "    'marks': [200, 210, 190, 222, 199]\n",
    "})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "    'student_id': ['S4','S5','S6','S7','S8'],\n",
    "    'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'],\n",
    "    'marks': [201, 200, 198, 219, 201]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n"
     ]
    }
   ],
   "source": [
    "# 1. Write a Pandas program to join the two given dataframes along rows and assign all data.\n",
    "df_result = pd.concat([student_data1, student_data2])\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  student_id              name  marks student_id              name  marks\n",
      "0         S1  Danniella Fenton    200         S4  Scarlette Fisher    201\n",
      "1         S2      Ryder Storey    210         S5  Carla Williamson    200\n",
      "2         S3      Bryce Jensen    190         S6       Dante Morse    198\n",
      "3         S4         Ed Bernal    222         S7    Kaiser William    219\n",
      "4         S5       Kwame Morin    199         S8   Madeeha Preston    201\n"
     ]
    }
   ],
   "source": [
    "# 2. Write a Pandas program to join the two given dataframes along columns and assign all data.\n",
    "df_result = pd.concat([student_data1, student_data2], axis=1)\n",
    "\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  student_id              name marks\n",
      "0         S1  Danniella Fenton   200\n",
      "1         S2      Ryder Storey   210\n",
      "2         S3      Bryce Jensen   190\n",
      "3         S4         Ed Bernal   222\n",
      "4         S5       Kwame Morin   199\n",
      "5         S6           Vu Tran   202\n"
     ]
    }
   ],
   "source": [
    "# 3. Write a Pandas program to append rows to an existing DataFrame and display the combined data.\n",
    "new_student = pd.Series(['S6', 'Vu Tran', 202], index=student_data1.columns)\n",
    "\n",
    "new_student_data = pd.concat([student_data1, new_student.to_frame().T], ignore_index=True)\n",
    "\n",
    "print(new_student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  student_id              name marks\n",
      "0         S1  Danniella Fenton   200\n",
      "1         S2      Ryder Storey   210\n",
      "2         S3      Bryce Jensen   190\n",
      "3         S4         Ed Bernal   222\n",
      "4         S5       Kwame Morin   199\n",
      "5         S6           Vu Tran   202\n",
      "6         S7         Phat Tran   250\n"
     ]
    }
   ],
   "source": [
    "# 4. Write a Pandas program to append a list of dictioneries or series to a existing DataFrame and display the combined data.\n",
    "list_new_student = [{'student_id': 'S6', 'name': 'Vu Tran', 'marks': 202},\n",
    "                    {'student_id': 'S7', 'name': 'Phat Tran', 'marks': 250}]\n",
    "\n",
    "# Create a new dataframe, convert each dict to a series, then append to the new dataframe\n",
    "new_student_data = student_data1.copy()\n",
    "\n",
    "for student in list_new_student:\n",
    "    new_student_data = pd.concat([new_student_data, pd.Series(student).to_frame().T], ignore_index=True)\n",
    "\n",
    "print(new_student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "  student_id              name  marks  exam_id\n",
      "0         S1  Danniella Fenton    200       23\n",
      "1         S2      Ryder Storey    210       45\n",
      "2         S3      Bryce Jensen    190       12\n",
      "3         S4         Ed Bernal    222       67\n",
      "4         S5       Kwame Morin    199       21\n",
      "5         S4  Scarlette Fisher    201       67\n",
      "6         S5  Carla Williamson    200       21\n",
      "7         S6       Dante Morse    198       45\n",
      "8         S7    Kaiser William    219       56\n",
      "9         S8   Madeeha Preston    201       89\n"
     ]
    }
   ],
   "source": [
    "# 5. Write a Pandas program to join the two given dataframes along rows and merge with another dataframe along the common column id.\n",
    "student_data3 = pd.DataFrame({\n",
    "    'student_id': ['S1','S2','S3','S4','S5'],\n",
    "    'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
    "    'marks': [200, 210, 190, 222, 199]\n",
    "})\n",
    "\n",
    "student_data4 = pd.DataFrame({\n",
    "    'student_id': ['S4','S5','S6','S7','S8'],\n",
    "    'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'],\n",
    "    'marks': [201, 200, 198, 219, 201]\n",
    "})\n",
    "\n",
    "student_data5 = pd.DataFrame({\n",
    "    'student_id': ['S1','S2','S3','S4','S5', 'S6', 'S7', 'S8'],\n",
    "    'exam_id': [23, 45, 12, 67, 21, 45, 56, 89]})\n",
    "\n",
    "df_result = pd.concat([student_data3, student_data4])\n",
    "df_result = pd.merge(df_result, student_data5, on='student_id')\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  student_id       name_x  marks_x            name_y  marks_y\n",
      "0         S4    Ed Bernal      222  Scarlette Fisher      201\n",
      "1         S5  Kwame Morin      199  Carla Williamson      200\n"
     ]
    }
   ],
   "source": [
    "# 6. Write a Pandas program to join the two dataframes using the common column of both dataframes.\n",
    "df_result = pd.merge(student_data3, student_data4, on='student_id')\n",
    "print(df_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
